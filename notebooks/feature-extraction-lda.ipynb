{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"../data\"\n",
    "ABUNDANCE_FILE = \"abundance_with_unique.csv\"\n",
    "ABUNDANCE_START = 212\n",
    "\n",
    "PERCENT_INFO = 0.95\n",
    "TEST_SPLIT = 0.2\n",
    "SEED = 42\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "LAYERS = [1024, 512, 256, 128, 64, 64, 32, 32]\n",
    "LEARNING_RATE = 0.00005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "abundance_data = pd.read_csv(os.path.join(DATA_FOLDER, ABUNDANCE_FILE), low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = abundance_data.iloc[:, :ABUNDANCE_START]\n",
    "abundance = abundance_data.iloc[:, ABUNDANCE_START:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = abundance.values\n",
    "Y_train = metadata['disease']\n",
    "\n",
    "healthy_classes = ['n', 'leaness', 'nd', ' -', 'n_relative', '-']\n",
    "\n",
    "Y_train = Y_train.apply(lambda x: 'healthy' if x in healthy_classes else x)\n",
    "Y_train = Y_train.apply(lambda x: 'psoriasis' if x == 'y' else x)\n",
    "\n",
    "classes = Y_train.unique()\n",
    "n_classes = len(classes)\n",
    "Y_train = pd.Categorical(Y_train, categories=classes).codes\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14],\n",
      "      dtype=int8), array([2692,  164,   52,  148,   25,   36,  118,    5,   10,    1,  223,\n",
      "         49,   48,   26,   13]))\n"
     ]
    }
   ],
   "source": [
    "type(X_train_scaled), X_train_scaled.shape, type(Y_train), Y_train.shape\n",
    "\n",
    "print(np.unique(Y_train, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "X_train_lda = lda.fit_transform(X_train_scaled, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of components is 14\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of components is\", X_train_lda.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdundancaDataset(Dataset):\n",
    "    def __init__(self, data, target):\n",
    "        self.X = data\n",
    "        self.Y = target\n",
    "        \n",
    "        print(\"X shape\", self.X.shape)\n",
    "        print(\"Y shape\", self.Y.shape)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.X[idx], dtype=torch.float32), torch.tensor(self.Y[idx], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape (2888, 14)\n",
      "Y shape (2888,)\n",
      "X shape (722, 14)\n",
      "Y shape (722,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_train_lda, Y_train, test_size=TEST_SPLIT, random_state=SEED)\n",
    "\n",
    "train_dataset = AdundancaDataset(X_train, Y_train)\n",
    "test_dataset = AdundancaDataset(X_test, Y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, idim, odim, layers, batch_norm=True):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Sequential()\n",
    "        \n",
    "        for i, layer in enumerate(layers):\n",
    "            if i == 0:\n",
    "                self.layers.add_module(\"fc{}\".format(i), nn.Linear(idim, layer))\n",
    "            else:\n",
    "                self.layers.add_module(\"fc{}\".format(i), nn.Linear(layers[i-1], layer))\n",
    "            \n",
    "            if batch_norm:\n",
    "                self.layers.add_module(\"bn{}\".format(i), nn.BatchNorm1d(layer))\n",
    "            \n",
    "            self.layers.add_module(\"relu{}\".format(i), nn.ReLU())\n",
    "            \n",
    "        self.layers.add_module(\"fc{}\".format(len(layers)), nn.Linear(layers[-1], odim))\n",
    "        self.layers.add_module(\"softmax\", nn.Softmax(dim=1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "def train(model, data_loader, criterion, optimizer):\n",
    "    \"\"\"\n",
    "    Generic training function\n",
    "    \"\"\"\n",
    "    model.train() # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    for _, data in enumerate(data_loader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad() # Zero the gradients\n",
    "        \n",
    "        outputs = model(inputs) # Forward pass\n",
    "        loss = criterion(outputs, labels) # Compute loss\n",
    "        loss.backward() # Backward pass\n",
    "        optimizer.step() # Update weights\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(data_loader)\n",
    "\n",
    "def evaluate(model, data_loader, criterion):\n",
    "    \"\"\"\n",
    "    Generic evaluation function    \n",
    "    \"\"\"\n",
    "    model.eval() # Set model to evaluation mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(data_loader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            predicted_labels.extend(predicted.cpu().numpy())\n",
    "            \n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    return running_loss / len(data_loader), correct / total, true_labels, predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss: 2.6880 Train Accuracy: 0.5048 Test Accuracy: 0.4806\n",
      "Epoch: 10 Train Loss: 2.3966 Train Accuracy: 0.8269 Test Accuracy: 0.8393\n",
      "Epoch: 20 Train Loss: 2.1927 Train Accuracy: 0.8359 Test Accuracy: 0.8380\n",
      "Epoch: 30 Train Loss: 2.0771 Train Accuracy: 0.8684 Test Accuracy: 0.8504\n",
      "Epoch: 40 Train Loss: 2.0031 Train Accuracy: 0.8913 Test Accuracy: 0.8573\n",
      "Epoch: 50 Train Loss: 1.9620 Train Accuracy: 0.9034 Test Accuracy: 0.8573\n",
      "Epoch: 60 Train Loss: 1.9487 Train Accuracy: 0.9020 Test Accuracy: 0.8476\n",
      "Epoch: 70 Train Loss: 1.9403 Train Accuracy: 0.9179 Test Accuracy: 0.8407\n",
      "Epoch: 80 Train Loss: 1.9225 Train Accuracy: 0.9110 Test Accuracy: 0.8352\n",
      "Epoch: 90 Train Loss: 1.9176 Train Accuracy: 0.9072 Test Accuracy: 0.8504\n",
      "Epoch: 100 Train Loss: 1.9164 Train Accuracy: 0.9193 Test Accuracy: 0.8421\n",
      "Epoch: 110 Train Loss: 1.9147 Train Accuracy: 0.9176 Test Accuracy: 0.8393\n",
      "Epoch: 120 Train Loss: 1.9204 Train Accuracy: 0.9214 Test Accuracy: 0.8421\n",
      "Epoch: 130 Train Loss: 1.9019 Train Accuracy: 0.9411 Test Accuracy: 0.8366\n",
      "Epoch: 140 Train Loss: 1.8997 Train Accuracy: 0.9449 Test Accuracy: 0.8490\n",
      "Epoch: 150 Train Loss: 1.8990 Train Accuracy: 0.9197 Test Accuracy: 0.8463\n",
      "Epoch: 160 Train Loss: 1.8892 Train Accuracy: 0.9404 Test Accuracy: 0.8573\n",
      "Epoch: 170 Train Loss: 1.8882 Train Accuracy: 0.9456 Test Accuracy: 0.8449\n",
      "Epoch: 180 Train Loss: 1.8893 Train Accuracy: 0.9373 Test Accuracy: 0.8352\n",
      "Epoch: 190 Train Loss: 1.8793 Train Accuracy: 0.9494 Test Accuracy: 0.8463\n",
      "Epoch: 200 Train Loss: 1.8852 Train Accuracy: 0.9515 Test Accuracy: 0.8449\n",
      "Epoch: 210 Train Loss: 1.8797 Train Accuracy: 0.9477 Test Accuracy: 0.8421\n",
      "Epoch: 220 Train Loss: 1.8810 Train Accuracy: 0.9546 Test Accuracy: 0.8601\n",
      "Epoch: 230 Train Loss: 1.8754 Train Accuracy: 0.9533 Test Accuracy: 0.8476\n",
      "Epoch: 240 Train Loss: 1.8741 Train Accuracy: 0.9543 Test Accuracy: 0.8435\n",
      "Epoch: 250 Train Loss: 1.8736 Train Accuracy: 0.9571 Test Accuracy: 0.8393\n",
      "Epoch: 260 Train Loss: 1.8720 Train Accuracy: 0.9494 Test Accuracy: 0.8338\n",
      "Epoch: 270 Train Loss: 1.8689 Train Accuracy: 0.9602 Test Accuracy: 0.8241\n",
      "Epoch: 280 Train Loss: 1.8715 Train Accuracy: 0.9643 Test Accuracy: 0.8380\n",
      "Epoch: 290 Train Loss: 1.8619 Train Accuracy: 0.9664 Test Accuracy: 0.8338\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "model = MLP(idim=X_train_lda.shape[1], odim=n_classes, layers=LAYERS)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for epoch in range(300):\n",
    "    train_loss = train(model, train_loader, criterion, optimizer)\n",
    "    _, train_accuracy, _, _ = evaluate(model, train_loader, criterion)\n",
    "    _, test_accuracy, _, _ = evaluate(model, test_loader, criterion)\n",
    "    \n",
    "    if(epoch % 10 == 0):\n",
    "        print(\"Epoch: {} Train Loss: {:.4f} Train Accuracy: {:.4f} Test Accuracy: {:.4f}\".format(epoch, train_loss, train_accuracy, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.8532 Train Accuracy: 0.9650\n",
      "[[2135   10    0    0    0    7    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [  36   88    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [   1    0   44    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [   0    0    0  118    0    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [   0    0    0    0   20    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [   5    0    0    0    0   22    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [  11    0    0    0    0    0   78    0    0    0    1    0    0    0\n",
      "     0]\n",
      " [   2    3    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [   7    0    0    0    0    1    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [   1    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [   5    0    0    1    0    0    0    0    0    0  180    0    0    0\n",
      "     0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    1   37    0    0\n",
      "     0]\n",
      " [   2    0    0    0    0    0    0    0    0    0    0    0   38    0\n",
      "     0]\n",
      " [   2    1    0    1    0    0    0    0    0    0    0    1    0   17\n",
      "     1]\n",
      " [   1    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    10]]\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "                   healthy       0.97      0.99      0.98      2152\n",
      "                   obesity       0.86      0.71      0.78       124\n",
      "            stec2-positive       1.00      0.98      0.99        45\n",
      "    ibd_ulcerative_colitis       0.98      1.00      0.99       118\n",
      "         ibd_crohn_disease       1.00      1.00      1.00        20\n",
      "                 psoriasis       0.73      0.81      0.77        27\n",
      "                 cirrhosis       1.00      0.87      0.93        90\n",
      "                     obese       0.00      0.00      0.00         5\n",
      "                overweight       0.00      0.00      0.00         8\n",
      "               underweight       0.00      0.00      0.00         1\n",
      "                       t2d       0.99      0.97      0.98       186\n",
      "impaired_glucose_tolerance       0.97      0.97      0.97        38\n",
      "                    cancer       1.00      0.95      0.97        40\n",
      "             small_adenoma       1.00      0.74      0.85        23\n",
      "             large_adenoma       0.91      0.91      0.91        11\n",
      "\n",
      "                  accuracy                           0.97      2888\n",
      "                 macro avg       0.76      0.73      0.74      2888\n",
      "              weighted avg       0.96      0.97      0.96      2888\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_accuracy, true_labels, predicted_labels = evaluate(model, train_loader, criterion)\n",
    "\n",
    "print(\"Train Loss: {:.4f} Train Accuracy: {:.4f}\".format(train_loss, train_accuracy))\n",
    "\n",
    "print(confusion_matrix(true_labels, predicted_labels, labels=range(len(classes))))\n",
    "print(classification_report(true_labels, predicted_labels, target_names=classes, labels=range(len(classes)), zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.9810 Test Accuracy: 0.8366\n",
      "[[510   9   0   8   0   0   0   0   0   0  11   1   0   0   1]\n",
      " [ 26  14   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  2   0   5   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  7   0   0  22   1   0   0   0   0   0   0   0   0   0   0]\n",
      " [  3   0   0   0   2   0   0   0   0   0   0   0   0   0   0]\n",
      " [  2   0   0   0   0   7   0   0   0   0   0   0   0   0   0]\n",
      " [ 14   0   0   0   0   0  12   0   0   0   1   0   0   1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  2   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 13   0   0   1   0   0   1   0   0   0  21   1   0   0   0]\n",
      " [  3   0   0   0   0   0   0   0   0   0   4   4   0   0   0]\n",
      " [  2   0   0   0   0   0   0   0   0   0   1   0   5   0   0]\n",
      " [  3   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   2]]\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "                   healthy       0.87      0.94      0.91       540\n",
      "                   obesity       0.61      0.35      0.44        40\n",
      "            stec2-positive       1.00      0.71      0.83         7\n",
      "    ibd_ulcerative_colitis       0.71      0.73      0.72        30\n",
      "         ibd_crohn_disease       0.67      0.40      0.50         5\n",
      "                 psoriasis       1.00      0.78      0.88         9\n",
      "                 cirrhosis       0.92      0.43      0.59        28\n",
      "                     obese       0.00      0.00      0.00         0\n",
      "                overweight       0.00      0.00      0.00         2\n",
      "               underweight       0.00      0.00      0.00         0\n",
      "                       t2d       0.55      0.57      0.56        37\n",
      "impaired_glucose_tolerance       0.67      0.36      0.47        11\n",
      "                    cancer       1.00      0.62      0.77         8\n",
      "             small_adenoma       0.00      0.00      0.00         3\n",
      "             large_adenoma       0.67      1.00      0.80         2\n",
      "\n",
      "                 micro avg       0.84      0.84      0.84       722\n",
      "                 macro avg       0.58      0.46      0.50       722\n",
      "              weighted avg       0.83      0.84      0.82       722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy, true_labels, predicted_labels = evaluate(model, test_loader, criterion)\n",
    "\n",
    "print(\"Test Loss: {:.4f} Test Accuracy: {:.4f}\".format(test_loss, test_accuracy))\n",
    "\n",
    "print(confusion_matrix(true_labels, predicted_labels, labels=range(len(classes))))\n",
    "print(classification_report(true_labels, predicted_labels, target_names=classes, labels=range(len(classes)), zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
